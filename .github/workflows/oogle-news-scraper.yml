name: Google News Scraper

on:
  schedule:
    # Runs every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch: # Allows manual triggering

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 1
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 feedparser pytz
          
      - name: Run scraper script
        run: python .github/scripts/news_scraper.py
        env:
          KEYWORDS: "ai, machine learning, data science" # Change these to your desired keywords
      
      - name: Configure Git
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          
      - name: Commit and push if README changed
        run: |
          git add README.md
          git diff --quiet && git diff --staged --quiet || git commit -m "Update news items: $(date +'%Y-%m-%d %H:%M:%S')"
          git push
